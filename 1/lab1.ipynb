{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save this file as studentid_lab1.ipynb**\n",
    "(Your student-id is the number shown on your student card.)\n",
    "\n",
    "E.g. if your student-id is 12345678, then:\n",
    "12345678_lab1.ipynb.\n",
    "\n",
    "**This will be parsed by a regexp, so please double-check your filename.**\n",
    "\n",
    "Before you turn this problem in, please make sure everything runs correctly. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All). Note, that **you are not allowed to use Google Colab**.\n",
    "\n",
    "**Make sure you fill in your code when you will see the following tags: begin solution and end solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Maximum likelihood estimation, Linear Regression and Overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94becb83b0877b0d427727350af06325",
     "grade": false,
     "grade_id": "cell-447a8ab4c82429ab",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Machine Learning 1, September/October 2023\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in this IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact your TA.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Refer to last week's lab notes, i.e. http://docs.scipy.org/doc/, if you are unsure about what function to use. There are different correct ways to implement each problem!\n",
    "* For this lab, your regression solutions should be in closed form, i.e., should not perform iterative gradient-based optimization but find the exact optimum directly.\n",
    "*Use the provided test boxes to check if your answers are correct.\n",
    "* **Do not change the arguments in our functions!**\n",
    "* **Do not remove or add new cells. If you do you should expect a penalty in your assignment!**\n",
    "\n",
    "## Relevant materials for this assignment\n",
    "\n",
    "* Material week 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c278ee9abc89a5ef5d829c1049141d2",
     "grade": false,
     "grade_id": "cell-a31fbe1e5a0de9bb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.rcParams[\"figure.figsize\"] = [20,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34b7d99a00f6eade32dc3217f47acee",
     "grade": false,
     "grade_id": "cell-369c3e293a3f9c73",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell makes sure that you have all the necessary libraries installed\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from importlib.util import find_spec, module_from_spec\n",
    "\n",
    "def check_newer_version(version_inst, version_nec):\n",
    "    version_inst_split = version_inst.split('.')\n",
    "    version_nec_split = version_nec.split('.')\n",
    "    for i in range(min(len(version_inst_split), len(version_nec_split))):\n",
    "        if int(version_nec_split[i]) > int(version_inst_split[i]):\n",
    "            return False\n",
    "        elif int(version_nec_split[i]) < int(version_inst_split[i]):\n",
    "            return True\n",
    "    return True\n",
    "\n",
    "\n",
    "module_list = [('jupyter', '1.0.0'), \n",
    "               ('matplotlib', '3.5.1'), \n",
    "               ('numpy', '1.22.3'), \n",
    "               ('python', '3.9.5'), \n",
    "               ('sklearn', '1.1.1'), \n",
    "               ('scipy', '1.7.3'), \n",
    "               ('nb_conda', '2.2.1')]\n",
    "\n",
    "packages_correct = True\n",
    "packages_errors = []\n",
    "\n",
    "for module_name, version in module_list:\n",
    "    if module_name == 'scikit-learn':\n",
    "        module_name = 'sklearn'\n",
    "    if 'python' in module_name:\n",
    "        python_version = platform.python_version()\n",
    "        if not check_newer_version(python_version, version):\n",
    "            packages_correct = False\n",
    "            error = f'Update {module_name} to version {version}. Current version is {python_version}.'\n",
    "            packages_errors.append(error) \n",
    "            print(error)\n",
    "    else:\n",
    "        spec = find_spec(module_name)\n",
    "        if spec is None:\n",
    "            packages_correct = False\n",
    "            error = f'Install {module_name} with version {version} or newer, it is required for this assignment!'\n",
    "            packages_errors.append(error) \n",
    "            print(error)\n",
    "        else:\n",
    "            x = __import__(module_name)\n",
    "            if hasattr(x, '__version__') and not check_newer_version(x.__version__, version):\n",
    "                packages_correct = False\n",
    "                error = f'Update {module_name} to version {version}. Current version is {x.__version__}.'\n",
    "                packages_errors.append(error) \n",
    "                print(error)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    packages_correct = False\n",
    "    error = \"\"\"Please, don't use google colab!\n",
    "It will make it much more complicated for us to check your homework as it merges all the cells into one.\"\"\"\n",
    "    packages_errors.append(error) \n",
    "    print(error)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "packages_errors = '\\n'.join(packages_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd5309776d11fcb49ffab39588776f0",
     "grade": false,
     "grade_id": "cell-5819bb5a7dd69748",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Maximum likelihood estimation\n",
    "\n",
    "### Probability theory (Background)\n",
    "In this section, we will formalize and refresh the basic notions of probability theory. Even though these notions are basic in the sense that they are used often and lie at the basis of all probability theory and statistics, they are quite tricky to fully grasp. Taking your time now to digest these notions will pay off later :)\n",
    "\n",
    "\n",
    "#### Sample spaces and event spaces\n",
    "\n",
    "\n",
    "Suppose that after a lecture, I randomly select one student from the course and record whether they are right-handed or left-handed, and then have them randomly select a student and again I record whether they are right-handed or left-handed. Of course, this experiment has a random element to it: if I repeat it multiple times, I can get different outcomes. We will use this experiment as our guiding example to introduce all notions. \n",
    "\n",
    "First of all, we can define a **sample space**. In essence, a sample space - denoted as $\\Omega$ - is just a set of possible outcomes we agree on. In our case, $\\Omega = \\{\\text{RR}, \\text{RL}, \\text{LR}, \\text{LL}\\}$, where 'LR' denotes that person one is left-handed and person two is right-handed, et cetera. Slightly more technical, we need to define an **event space**. That is, we need to choose to which subsets of the sample space - or, **events** - we care to assign probabilities. If in our so-called event space - denoted $\\mathcal{S}$ - we want to assign a probability to $\\{ \\text{LR}, \\text{RL} \\}$ - i.e. the event that there is exactly one left-handed person - we need to ensure that $\\{ \\text{LR}, \\text{RL} \\} \\in \\mathcal{S}$. This event space needs to satisfy a few requirements to ensure you can do regular probability theory:\n",
    "\n",
    "\n",
    "1.   The empty set is an event, i.e. $\\emptyset \\in \\mathcal{S}$.\n",
    "2.   If the union of two events is also an event, i.e. $\\alpha, \\beta \\in \\mathcal{S}$ implies that $\\alpha \\cup \\beta \\in \\mathcal{S}$.\n",
    "3.   The complement of some event is also an event, i.e. $\\alpha \\in \\mathcal{S}$ implies that $\\Omega \\setminus \\alpha \\in \\mathcal{S}$. \n",
    "\n",
    "Since $\\mathcal{S}$ is closed under these operations, it is also closed under other Boolean operations, such as intersection and set difference since we can define these operations in terms of unions and complements.\n",
    "\n",
    "\n",
    "#### Random variables and probability distributions\n",
    "\n",
    "\n",
    "\n",
    "One of the most important notions in probability theory is a **random variable**. You can think of a random variable as asking a question about this experiment, e.g. we might be interested in how many left-handed people there are in each experiment. What a random variable simply does, is tell us the answer to that question for each of the outcomes in the sample space, i.e. if we denote our random variable as $\\text{TotalLH}$, we would say that \n",
    "\n",
    "- $\\text{TotalLH}(\\text{RR}) = 0$, \n",
    "- $\\text{TotalLH}(\\text{RL}) = \\text{TotalLH}(\\text{LR}) = 1$, \n",
    "- $\\text{TotalLH}(\\text{LL}) = 2$. \n",
    "\n",
    "Note that therefore a random variable is not a variable but rather a function that maps from $\\Omega$ into $\\mathbb{R}$ in general. Also, since this mapping isn't random either, both 'random' and 'variable' do not make too much intuitive sense for this object. There is also a reverse mapping for this. Since \n",
    "\n",
    "$$\\text{TotalLH}(\\text{RL}) = \\text{TotalLH}(\\text{LR}) = 1,$$ \n",
    "\n",
    "we can also write that \n",
    "\n",
    "$$(\\text{TotalLH} = 1) = \\{\\text{LR, RL}\\}.$$\n",
    "\n",
    "This may look unfamiliar at first, but you have used this before very often: every time you write $P(X=x)$, you are considering the probability of the event described by the set $(X=x)$. \n",
    "\n",
    "\n",
    "Now, the last object we care about is a **probability distribution**. A probability distribution $P$ is a function that describes the probability of a random variable taking certain values. Assuming that roughly 10% of people are left-handed, we will guess for now that the probability of our experiment having only left-handed people is 0.01. This we would write as $P(\\text{TotalLH} = 2) = 0.01$. Please note that therefore a probability distribution is mapped from $P: \\mathcal{S} \\to \\mathbb{R}$. Formally, a probability distribution $P$ over $(\\Omega, \\mathcal{S})$ is a mapping from $\\mathcal{S}$ to real values that satisfies:\n",
    "\n",
    "1. All probabilities are non negative, i.e. $P(\\alpha) \\geq 0$ for all $\\alpha \\in \\mathcal{S}$\n",
    "2. The 'maximum' probability of the event that 'anything happens' is 1, i.e. $P(\\Omega) = 1$\n",
    "3. The probability that one of two disjoint events will occur is the sum of the probabilities of each event, i.e. $\\alpha, \\beta \\in \\mathcal{S}$ and $\\alpha \\cap \\beta = \\emptyset$, then $P(\\alpha \\cup \\beta) = P(\\alpha) + P(\\beta)$.\n",
    "\n",
    "These are the so-called **Kolmogorov Axioms**. You can read more about them here: https://en.wikipedia.org/wiki/Probability_axioms\n",
    "\n",
    "\n",
    "#### Why do we care? \n",
    "\n",
    "What is especially nice about looking at distributions for different random variables, is that we can find patterns in them / realize that different processes follow the same kind of distribution. For example, a random coin flip versus asking someone whether they're left-handed both follow the same kind of distribution, since both random variables assign probabilities to exactly two outcomes (even though the exact distributions might be different, i.e. the odd of getting heads in not necessarily the same as the odds of getting a right-handed person). This distribution is called a Bernoulli distribution. If the probability of a positive outcome for the random variable $\\text{X}$ is denoted as $p$, we write that $\\text{X} \\sim \\mathsf{Bernoulli}(p)$. So, our coin flip would follow a $\\mathsf{Bernoulli}(0.5)$, and out right-handedness experiment would follow a $\\mathsf{Bernoulli}(0.9)$, but both are Bernoullis. Here, you can find a list of many existing distributions: https://en.wikipedia.org/wiki/List_of_probability_distributions \n",
    "\n",
    "As you may guess, we say that $p=0.5$ because half of the time we flip a coin it lands on heads. But why is this a valid way of estimating that probability? That is exactly what we formalize with MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "656ebb77dda290cbd09accd9d93c88c5",
     "grade": false,
     "grade_id": "cell-6f6860b011fe1f0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implementing MLE Poisson distribution\n",
    "One of the most common distributions that assign a probability of all outcomes $n \\in \\mathbb{N}$ is the Poisson distribution. The Poisson distribution in general is used to assign probabilities to a random variable that describes the **number of events in a fixed interval of time/space**, e.g. how many emails you get per hour or the number of people that arrive to your restaurant per minute. We say that $\\text{X} \\sim \\mathsf{Poisson}(\\lambda)$ when\n",
    "\n",
    "$$P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}.$$\n",
    "\n",
    "This is what this distribution looks like for different values of $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9beb0cd2ed75e8382ff3f55fba1c0eb",
     "grade": false,
     "grade_id": "cell-b415386f0cb5a7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "support = np.arange(20)\n",
    "lambda_values = [3.0, 5.0, 7.0]\n",
    "\n",
    "for lambda_value in lambda_values:\n",
    "    val = poisson.pmf(support, lambda_value)\n",
    "    plt.plot(support, val, label=f'$\\lambda={lambda_value}$')\n",
    "\n",
    "plt.xticks(support)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb12610da1ab5bc84d9fa7089664af42",
     "grade": false,
     "grade_id": "cell-8953b49454321fce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implement log-likelihood (5pt)\n",
    "In the lectures, we have come across the likelihood and log-likelihood function. Implement the log likelihood function for the poisson distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "323158c224bb18edaf7c5bce8867cddd",
     "grade": false,
     "grade_id": "cell-370f8ee11fa2a322",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "def log_likelihood(lam, obs):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef37c18abe72433f6161a438804b981",
     "grade": true,
     "grade_id": "cell-92ff2c8607846479",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your function\n",
    "\n",
    "lam = 3.5\n",
    "observations = np.random.poisson(lam, size=500)\n",
    "lambda_values = np.linspace(1, 10, 1000)\n",
    "\n",
    "llh = log_likelihood(lambda_values, observations)\n",
    "assert llh.shape == (len(lambda_values,),), \"the shape of log-likelihoods is incorrect\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07aeb96a6eb7ede009b101c8aa9c89ea",
     "grade": false,
     "grade_id": "cell-e59ff1220d28f050",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In these cases, it can be worth to check yourself. When you plot the log likelihood, is the most likely value for lambda actually the value we specified? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1187959867836a755ea54224c748bd3",
     "grade": false,
     "grade_id": "cell-f030a01b87b44fe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(lambda_values, log_likelihood(lambda_values, observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88db960a1eb646647cb37ea216e68f56",
     "grade": false,
     "grade_id": "cell-4bbfaa8fc902b9bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implement MLE for Poisson (5pt)\n",
    "\n",
    "In class, you learned how to compute the MLE. Implement the MLE for $\\lambda$ in the Poisson distribution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e712bca21a365c8f51a28dcc2a42d81a",
     "grade": false,
     "grade_id": "cell-21589448936c58ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mle_poisson(obs):\n",
    "    \"\"\"Return MLE estimate of lambda parameter of a set of observations.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return mle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae0e61bc3f88ff7bd60455560b725df4",
     "grade": false,
     "grade_id": "cell-5cd133db7ad031a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Again, you can check yourself. In the following cell, you can test if your MLE estimate is close to the lambda value specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f523aa12f25e48eb7a99c17d98b9203",
     "grade": true,
     "grade_id": "cell-f54e4def6001adec",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mle = mle_poisson(observations)\n",
    "print(mle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fb1cc250dc5b8d73306834ac74c34b1",
     "grade": false,
     "grade_id": "cell-1e000d5c1c4f2199",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Parametrizing distributions (5pt)\n",
    "\n",
    "Suppose we want to predict is given student will do pass the exam. The most basic thing we could do is define a random variable $\\text{DoesWell}$ that follows a Bernoulli distribution with the pass rate of the exam, e.g. if 80% of student pass we can say that for any student $\\text{DoesWell} \\sim \\mathsf{Bernoulli}(0.8)$. However, sometimes we may have information about a student, e.g. their average grade for the courses thusfar, and we want to use that information. So, we want to find a distribution $\\text{DoesWell} \\mid \\text{Grade}$. Maybe, we want to say that if a student has a $10$, they are 95% likely to pass the exam, if their grade is a $9$ they are 85% likely to pass the exam, et cetera. That is, we say that \n",
    "\n",
    "$$\\text{DoesWell} \\mid \\text{Grade}=g \\sim \\mathsf{Bernoulli}(\\frac{g - 0.5}{10}).$$\n",
    "\n",
    "Please note that in general we can use other functions $f$ to parameterize $Y \\mid X = x \\sim \\mathsf{Bernoulli}(f(x))$, e.g. a neural network.\n",
    "\n",
    "For each grade, sample from this Bernoulli distribution. You should use `np.random.binomial`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60363ff2f532ee713d952c31fbe2ff70",
     "grade": false,
     "grade_id": "cell-4033d8dcf5eeaa0c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sample_bernoulli(grades):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return does_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b8df22f57a3531fbafae306876a495b",
     "grade": true,
     "grade_id": "cell-2cb5b1518d745968",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "grades = np.random.randint(1, 11, 100)\n",
    "does_wells = sample_bernoulli(grades)\n",
    "\n",
    "assert does_wells.shape == (len(grades), )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d92955d53672362bee9d39e52dc2698e",
     "grade": false,
     "grade_id": "cell-29bfc64d7a75b9d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a sanity check: how many people did well that had a ten for the assignments? And what about people that had a one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3137107ced2cd871446664ccd7650a9",
     "grade": false,
     "grade_id": "cell-505d034435d52b27",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### Generate periodic data (5 points)\n",
    "Write a method `gen_sine(N)` that generates toy data like in fig 1.2 of Bishop's book. The method should have a parameter $N$, and should return $N$-dimensional vectors $\\mathbf{x}$ and $\\mathbf{t}$, where $\\mathbf{x}$ contains evenly spaced values from 0 to (including) 2$\\pi$, and the elements $t_i$ of $\\mathbf{t}$ are distributed according to:\n",
    "\n",
    "$$t_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2)$$\n",
    "\n",
    "where $x_i$ is the $i$-th elements of $\\bf{x}$, the mean $\\mu_i = \\sin(x_i)$ and the standard deviation $\\sigma = 0.25$. You can make use of `np.random.normal()` (Hint: Double check its input parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30aed6e34ece9a80b25a90160e998019",
     "grade": false,
     "grade_id": "cell-1c8c68d862f80f7e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gen_sine(n):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return x, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06c7e4b785bfefb251544e053366c004",
     "grade": true,
     "grade_id": "cell-afc3c8025a62af85",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "np.random.seed(42)\n",
    "N = 10\n",
    "x, t = gen_sine(N)\n",
    "\n",
    "assert x.shape == (N,), \"the shape of x is incorrect\"\n",
    "assert t.shape == (N,), \"the shape of t is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70dcca9862cb1c1482f87f9fa21a3dc9",
     "grade": false,
     "grade_id": "cell-22a999e8760129f8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Polynomial regression (10 points)\n",
    "\n",
    "Write a method `fit_polynomial(x, t, M)` that finds the maximum-likelihood solution of an _unregularized_ $M$-th order polynomial for some dataset `x`. The error function to minimize w.r.t. $\\mathbf{w}$ is:\n",
    "\n",
    "$E(\\mathbf{w}) = \\frac{1}{2} (\\mathbf{\\Phi} \\mathbf{w} - \\mathbf{t})^T(\\mathbf{\\Phi} \\mathbf{w} - \\mathbf{t})$\n",
    "\n",
    "where $\\mathbf{\\Phi}$ is the _feature matrix_ (or _design matrix_) as explained in Bishop's book at section 3.1.1, $\\mathbf{t}$ is the vector of target values. Your method should return a vector $\\mathbf{w}$ with the maximum-likelihood parameter estimates, as well as the _feature matrix_ $\\mathbf{\\Phi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5f21a1de6f35ff5c520db69540d71c7",
     "grade": false,
     "grade_id": "cell-27b0d6f1bcdeb97b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def designmatrix(x, M): # it is highly recommended to write a helper function that computes Phi\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def fit_polynomial(x, t, M):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return w_ml, Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed92cddb718e1dd55d7a0d1cc1d623a7",
     "grade": true,
     "grade_id": "cell-7e0f87e75d7c82aa",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "m = 2\n",
    "w, Phi = fit_polynomial(x,t,m)\n",
    "\n",
    "assert w.shape == (m+1,), \"The shape of w is incorrect\"\n",
    "assert Phi.shape == (N, m+1), \"The shape of Phi is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cab15eadee5610035bb2b4297d8825af",
     "grade": false,
     "grade_id": "cell-f4d51f8338ebdb54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Plot (check yourself)\n",
    "Sample a dataset with $N=10$, and fit four polynomials with $M \\in (0, 2, 4, 8)$.\n",
    "For each value of $M$, plot the prediction function, along with the data and the original sine function. The resulting figure should look similar to fig 1.4 of the Bishop's book. Note that you can use matplotlib's `plt.pyplot(.)` functionality for creating grids of figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c39c94c54ea1310a3a12c4b5a84774a",
     "grade": false,
     "grade_id": "cell-2597ee45cb3998ed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Regularized linear regression (10 points)\n",
    "\n",
    "Write a method `fit_polynomial_reg(x, t, M, lamb)` that fits a _regularized_ $M$-th order polynomial to the periodic data, as discussed in the lectures, where `lamb` is the regularization term _lambda_. (Note that 'lambda' cannot be used as a variable name in Python since it has a special meaning). The error function to minimize w.r.t. $\\mathbf{w}$:\n",
    "\n",
    "$E(\\mathbf{w}) = \\frac{1}{2} (\\mathbf{\\Phi}\\mathbf{w}- \\mathbf{t})^T(\\mathbf{\\Phi}\\mathbf{w}- \\mathbf{t}) + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}$\n",
    "\n",
    "\n",
    "The function should return $\\mathbf{w}$ and $ \\mathbf{\\Phi} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc76736fba956e5d9cc51a318c2507c3",
     "grade": false,
     "grade_id": "cell-9fe81fd5537daff9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_reg(x, t, m, lamb):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return w_ml, Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "385d6b45a599e72289ac08f2c948303d",
     "grade": true,
     "grade_id": "cell-a2e561cbc5a4140b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "m = 2\n",
    "lamb = 0.1\n",
    "w, Phi = fit_polynomial_reg(x,t,m, lamb)\n",
    "\n",
    "assert w.shape == (m+1,), \"The shape of w is incorrect\"\n",
    "assert Phi.shape == (N, m+1), \"The shape of w is incorrect\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a63aee7ed332064df71371e8954adb6",
     "grade": false,
     "grade_id": "cell-f471e0e0ddf7667a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Bayesian Linear (Polynomial) Regression\n",
    "\n",
    "\n",
    "### Sine 2 (5 points)\n",
    "\n",
    "Write a function `gen_sine2(N)` that behaves identically to `gen_sine(N)` except that the generated values $x_i$ are not linearly spaced, but drawn from a uniform distribution between $0$ and $2 \\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "734894a81470d4d49711de0c90998d3e",
     "grade": false,
     "grade_id": "cell-36addc88e1b3fe1d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gen_sine2(n):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return x, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7003ef4307addbc6046a90a60fa9a83c",
     "grade": true,
     "grade_id": "cell-57a847b66fb591af",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "np.random.seed(42)\n",
    "N = 10\n",
    "x, t = gen_sine2(N)\n",
    "\n",
    "assert x.shape == (N,), \"the shape of x is incorrect\"\n",
    "assert t.shape == (N,), \"the shape of t is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a6540194fbaf2a17462fbbdd67316af",
     "grade": false,
     "grade_id": "cell-61f32a9b299aa500",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Compute Posterior (15 points)\n",
    "\n",
    "You're going to implement a Bayesian linear regression model, and fit it to the periodic data. Your regression model has a zero-mean isotropic Gaussian prior over the parameters, governed by a single (scalar) precision parameter $\\alpha$, i.e.:\n",
    "\n",
    "$$p(\\mathbf{w} \\;|\\; \\alpha) = \\mathcal{N}(\\mathbf{w} \\;|\\; 0, \\alpha^{-1} \\mathbf{I})$$\n",
    "\n",
    "The covariance and mean of the posterior are given by:\n",
    "\n",
    "$$\\mathbf{S}_N= \\left( \\alpha \\mathbf{I} + \\beta \\mathbf{\\Phi}^T \\mathbf{\\Phi} \\right)^{-1} $$\n",
    "$$\\mathbf{m}_N = \\beta\\; \\mathbf{S}_N \\mathbf{\\Phi}^T \\mathbf{t}$$\n",
    "\n",
    "where $\\alpha$ is the precision of the predictive distribution, and $\\beta$ is the noise precision. \n",
    "See MLPR chapter 3.3 for background.\n",
    "\n",
    "Write a method `fit_polynomial_bayes(x, t, M, alpha, beta)` that returns the mean $\\mathbf{m}_N$ and covariance $\\mathbf{S}_N$ of the posterior for a $M$-th order polynomial. In addition it should return the design matrix $\\mathbf{\\Phi}$. The arguments `x`, `t` and `M` have the same meaning as in question 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a945f997e9dec6b173c23a922ef773b3",
     "grade": false,
     "grade_id": "cell-24d68ce462db8f40",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_bayes(x, t, M, alpha, beta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return m, S, Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57b6869c4ee7ece5b4ecc93c5d8b3d0b",
     "grade": true,
     "grade_id": "cell-5cf266fca46cd4e9",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "M = 2\n",
    "alpha = 0.6\n",
    "beta = 16\n",
    "m, S, Phi = fit_polynomial_bayes(x, t, M, alpha, beta)\n",
    "\n",
    "assert m.shape == (M+1,), \"the shape of m is incorrect\" \n",
    "assert S.shape == (M+1, M+1), \"the shape of S is incorrect\"\n",
    "assert Phi.shape == (N, M+1), \"the shape of Phi is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e42b5a4ac3178d51a8482b9651766d7c",
     "grade": false,
     "grade_id": "cell-471f21c230ca4203",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Prediction (10 points)\n",
    "\n",
    "The predictive distribution of Bayesian linear regression is:\n",
    "\n",
    "$$ p(t \\;|\\; \\mathbf{x}, \\mathbf{t}, \\alpha, \\beta) = \\mathcal{N}(t \\;|\\; \\mathbf{m}_N^T \\phi(\\mathbf{x}), \\sigma_N^2(\\mathbf{x}))$$\n",
    "\n",
    "$$ \\sigma_N^2 = \\frac{1}{\\beta} + \\phi(\\mathbf{x})^T \\mathbf{S}_N \\phi(\\mathbf{x}) $$\n",
    "\n",
    "where $\\phi(\\mathbf{x})$ are the computed features for a new datapoint $\\mathbf{x}$, and $t$ is the predicted variable for datapoint $\\mathbf{x}$. \n",
    "\n",
    "Write a function that `predict_polynomial_bayes(x, m, S, beta)` that returns the predictive mean, variance and design matrix $\\mathbf{\\Phi}$ given a new datapoint `x`, posterior mean `m`, posterior variance `S` and a choice of model variance `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45fb4bc1bc26e2e2865d96eee138c9db",
     "grade": false,
     "grade_id": "cell-865ac2a455500d4b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_polynomial_bayes(x, m, S, beta):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return mean, sigma, Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f36b9ca870925b0fc5229e429a95ca0",
     "grade": true,
     "grade_id": "cell-ecb92bcbe0131eb9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "np.random.seed(42)\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "m = np.random.rand(3)\n",
    "S = np.random.rand(3, 3)\n",
    "beta = 16\n",
    "mean, sigma, Phi = predict_polynomial_bayes(x, m, S, beta)\n",
    "\n",
    "assert mean.shape == (N,), \"the shape of mean is incorrect\"\n",
    "assert sigma.shape == (N,), \"the shape of sigma is incorrect\"\n",
    "assert Phi.shape == (N, m.shape[0]), \"the shape of Phi is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f22266caee8409acc8e462f78e6b69cb",
     "grade": false,
     "grade_id": "cell-50452fe12b83c7ce",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Plot predictive distribution (test yourself)\n",
    "\n",
    "Generate 10 datapoints with `gen_sine2(10)`. Compute the posterior mean and covariance for a Bayesian polynomial regression model with $M=4$, $\\alpha=\\frac{2}{5}$ and $\\beta=\\frac{1}{0.25^2}$.\n",
    "Plot the Bayesian predictive distribution, where you plot (for $x$ between 0 and $2 \\pi$) $t$'s predictive mean and the predictive standard deviation using `plt.fill_between(..., alpha=0.1)` (the alpha argument induces transparency).\n",
    "\n",
    "Include the datapoints in your plot.\n",
    "\n",
    "For a second plot, draw 100 samples from the parameters' posterior distribution. Each of these samples is a certain choice of parameters for 4-th order polynomial regression.\n",
    "\n",
    "Display each of these 100 polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can plot here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e25b773d072dd9f93e757774256558c671135decaea047ac398712eefa19005c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
